#pip install replicate diffusers torch torchvision peft transformers

# -*- coding: utf-8 -*-
"""Flux-consistent-image.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cX9cOcilAE2GKyBda814lrYTqVccfIlp

# Flux Image Consistency
"""


import replicate
import requests
import os
from PIL import Image
import json
import torch
import torchvision.transforms as transforms
from diffusers import StableDiffusionPipeline
from peft import LoraConfig, get_peft_model

# Set API Keys
REPLICATE_API_TOKEN = "r8_get_your_own_token"
os.environ["REPLICATE_API_TOKEN"] = REPLICATE_API_TOKEN

# Initialize Replicate client
client = replicate.Client()

# Function to get or create a model
def get_or_create_model(model_name, owner="sage-khan"):
    try:
        # Attempt to retrieve the existing model
        model = client.models.get(f"{owner}/{model_name}")
        print(f"‚úÖ Using existing model: {model_name}")
        return model
    except replicate.exceptions.ReplicateError as e:
        if "404" in str(e):
            print(f"‚ùå Model '{model_name}' not found. Creating a new one...")
        else:
            print(f"‚ùå Unexpected error: {e}")
            return None

    # Create a new model if not found
    model = client.models.create(
        name=model_name,
        owner=owner,
        visibility="public",  # or "private" if preferred
        description="Fine-tuned FLUX.1 model for custom concept",
        hardware="gpu-a100-large"
    )
    print(f"‚úÖ New model created: {model.name}")
    print(f"üîó Model URL: https://replicate.com/{owner}/{model.name}")
    return model

# Function to fine-tune the FLUX.1 model
def fine_tune_flux_model(training_data_path, trigger_word, model_name, steps=1000):
    model = get_or_create_model(model_name)

    if model is None:
        print("‚ùå Model creation failed. Cannot fine-tune.")
        return None

    # Ensure the dataset ZIP file exists
    if not os.path.exists(training_data_path):
        print(f"‚ùå Error: Training dataset '{training_data_path}' not found.")
        return None

    # Start the fine-tuning process
    with open(training_data_path, "rb") as training_data:
        training = client.trainings.create(
            version="ostris/flux-dev-lora-trainer:b6af14222e6bd9be257cbc1ea4afda3cd0503e1133083b9d1de0364d8568e6ef",
            input={
                "input_images": training_data,
                "trigger_word": trigger_word,
                "steps": steps
            },
            destination=f"{model.owner}/{model.name}"
        )

    print(f"üöÄ Training started: {training.status}")
    print(f"üîó Training URL: https://replicate.com/p/{training.id}")

    # Manually poll training status until it's complete
    while True:
        updated_training = client.trainings.get(training.id)
        print(f"‚è≥ Training status: {updated_training.status}")

        if updated_training.status in ["succeeded", "failed", "canceled"]:
            break  # Exit loop when training is complete

        time.sleep(30)  # Wait before checking again

    if updated_training.status == "succeeded":
        print(f"‚úÖ Training completed successfully: {updated_training.status}")
    else:
        print(f"‚ùå Training failed: {updated_training.status}")

    return model if updated_training.status == "succeeded" else None

# Main execution
if __name__ == "__main__":
    # Path to your training data ZIP file
    training_data_path = "./dataset.zip"  # Ensure this exists!

    # Unique trigger word for your fine-tuned concept
    trigger_word = "sagekhanai"   #or hugh-jackman-ai

    # Name for your fine-tuned model
    model_name = "sagekhanai"   #or jackmanai

    # Fine-tune the model
    fine_tuned_model = fine_tune_flux_model(training_data_path, trigger_word, model_name)

# Initialize the Replicate client
client = replicate.Client()

# Function to generate images using the fine-tuned model
def generate_images(model_name, model_version, prompt, num_images=4):
    print(f"üöÄ Generating images using model: {model_name}:{model_version}")

    try:
        # Run the model and generate output URLs
        outputs = replicate.run(
            f"{model_name}:{model_version}",  # Use model hash
            input={
                "model": "dev",
                "go_fast": False,
                "lora_scale": 1,
                "megapixels": "1",
                "num_outputs": num_images,
                "aspect_ratio": "1:1",
                "output_format": "webp",
                "guidance_scale": 3,
                "output_quality": 80,
                "prompt_strength": 0.8,
                "extra_lora_scale": 1,
                "num_inference_steps": 28,
                "prompt": prompt  # User-provided prompt
            }
        )

        if not outputs:
            print("‚ùå No images generated.")
            return []

        # Download and save generated images
        image_paths = []
        for idx, img_url in enumerate(outputs):
            image_response = requests.get(img_url)
            if image_response.status_code == 200:
                image_path = f"generated_image_{idx + 1}.webp"  # Ensure correct format
                with open(image_path, "wb") as f:
                    f.write(image_response.content)
                image_paths.append(image_path)
                print(f"‚úÖ Image saved: {image_path}")
            else:
                print(f"‚ùå Failed to download image {idx + 1}. Status Code: {image_response.status_code}")

        return image_paths

    except Exception as e:
        print(f"‚ùå Error during image generation: {e}")
        return []

# Main execution
if __name__ == "__main__":
    # Name of your fine-tuned model
    model_name = "sage-khan/jackmanai"

    # Model version hash (replace with your model version)
    model_version = "8d1bca17af8d2dd5ed00b7c8d68808a9e81cf16da24f1095aae754122ce879dd"

    # Prompt to generate images
    trigger_word = "sagekhanai"  # Or "hugh-jackman-ai"

    prompt = f"""
    Ultra-detailed, hyper-realistic scene of {trigger_word} piloting a cutting-edge Navy jet at high altitude,
    soaring through the clouds with afterburners glowing. Inside the advanced cockpit, illuminated by soft blue HUD lights,
    {trigger_word} is skillfully writing Morse code on a digital interface, glowing green signals appearing on the futuristic glass panel.
    The jet's metallic surface reflects golden sunlight, motion blur emphasizing high-speed movement.
    Aerial perspective with dynamic cinematic lighting, 8K resolution, photorealistic details,
    dramatic cloudscape, high-contrast shadows, {trigger_word}.
    """

    # Generate images
    generated_images = generate_images(model_name, model_version, prompt)

    # Display final message
    if generated_images:
        print(f"üé® Successfully generated and saved {len(generated_images)} images.")
    else:
        print("‚ùå No images were generated.")
